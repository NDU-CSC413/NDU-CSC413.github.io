# OpenMP

OpenMP is a compiler extension for parallel programming. The code is annotated with preprocessor directives(_pragma_) to help the compiler parallelize the code. Below are the instructions to use OpenMP for common platforms
1. GNU g++: add the openmp switch, i.e. ```-fopenmp```
1. Microsoft cl.exe: ```/fopenmp```
1. Visual C++: Project Properties->C/C++->Language->OpenMP support (select yes)

In all platforms one should include the header ```omp.h```.

## Fork/Join Pattern

In our coverage of OpenMP, We will rely heavily on the fork/join pattern, or single
program multiple data (SPMD) shown in the figure below.


![fig](/img/fork-join.png)

We have used this pattern extensively by explicitly creating and managing C++ threads. OpenMP will do most of that work for us.

The basic fork/join pattern is used in openMP as follows
```cpp
#pragma omp parallel
{
    code to be run by all threads
}

```
The ```#pragma omp parallel``` will create a parallel region. This is equivalent to creating
a number of threads at the beginning of the construct and joining them at the end.
Obviously, to do useful work each thread should work on a different part of the data. To do
so one you should be able to tell which thread is running. This accomplished by the 
```omp_get_thread_number()``` and ```omp_get_num_threads()``` calls.

We illustrate with the "hello world" of parallel programming, computing PI.
## Computing PI

Recall that PI can be computed numerically using the expression below

<div style="background-color:white">
<img src="https://render.githubusercontent.com/render/math?math=\pi=4\int_0^1\frac{dx}{1%2Bx^2}"></div>

We have done this computation before by explicitly creating C++ threads. In this example we let OpenMP do the bookkeeping for us.

```cpp
int main()
{
	const int num_steps = 1 << 28;
	const double dx = 1.0 / (double)num_steps;
	const int num_threads = 8;
	omp_set_num_threads(num_threads);
	double results[num_threads]{};
	double d = omp_get_wtime();
#pragma omp parallel 
	{
		int nthreads = omp_get_num_threads();
		int block_size = num_steps / nthreads;
		int idx = omp_get_thread_num();
		double midpoint;
		for (int i = idx*block_size; i<(idx+1)*block_size ; ++i) {
			midpoint = (i + 0.5) * dx;
			results[idx] += 4.0 / (1 + midpoint * midpoint);
		}
	}

	double r = 0;
	for (int i = 0; i < num_threads; ++i)
		r += results[i];
	std::cout<<r*dx << "\n";
	d = omp_get_wtime() - d;
	/* duration in ms */
	std::cout << 1000 * d << "\n";
}

```
The first OpenMP call is ```omp_set_num_threads```. This sets the maximum number of threads to be used.
Next is the ```omp parallel``` directive creates the fork/join pattern. Notice that we use ```omp_get_num_threads()```
to get the __actual__ number of threads being used. Usually this is the same value as ```num_threads``` but sometimes
OpenMP cannot allocate the requested number of threads so it uses a smaller number but __never__ larger. This is why
when the array ```results``` is allocated we make sure it is initialized to 0 so that in the sum of all values at the 
end we are adding zeros if the actual number of threads is less than requested.

The next important call is ```omp_get_thread_num``` which returns the thread number and therefore allow us to specify
on which region of the input the thread is acting on.

It is important to note that at the end of the ```omp parallel``` block, there is a hidden join, where the main thread
waits for all other threads to finish.

## False sharing


The line ```results[idx]+=4/(1+midpoint*point)``` is a pattern that we have seen before many times. Each thread
stores its partial result in a different location of the array and therefore there is __no contention__. Actually,
this line of code results in poor performance due to repeated cache update. We have not seen this effect before
because smart compilers (when optimization is used) usually optimize it away.

This problem is common enough that it was given a name: __false sharing__. The basic idea is that even though different
threads are writing to different locations in the array but those locations are on the same __cache line__ which forces cache invalidation/updates. The situation is shown in the figure below.

![fig](/img/false-sharing.png)


